# -*- coding: utf-8 -*-
"""LinearRegression.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZbuBypsY4T-S7PUj2zSfhq3vL6SLj_ko
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import matplotlib.pyplot as plt

# This code is for Jupyter Notebook only
# %matplotlib inline

# define data, and change list to array
x = [3, 21, 22, 34, 54, 34, 55, 67, 89, 99]
x = np.array(x)

y = [1, 10, 14, 34, 44, 36, 22, 67, 79, 90]
y = np.array(y)

# Show the effect of a scatter plot
plt.scatter(x, y)
plt.show()

# The basic linear regression model is wx+b, and since this is a two-dimensional space, the model is ax+b
def model(a, b, x):
    return a * x + b

# The most commonly used loss function of linear regression model is the loss function of mean variance difference
def loss_function(a, b, x, y):
    num = len(x)
    prediction = model(a, b, x)
    return (0.5 / num) * (np.square(prediction - y)).sum()

# The optimization function mainly uses partial derivatives to update two parameters a and b
def optimize(a, b, x, y):
    num = len(x)
    prediction = model(a, b, x)
    # Update the values of A and B by finding the partial derivatives of the loss function on a and b
    da = (1.0 / num) * ((prediction - y) * x).sum()
    db = (1.0 / num) * ((prediction - y).sum())
    a = a - Lr * da
    b = b - Lr * db
    return a, b

# iterated function, return a and b
def iterate(a, b, x, y, times):
    for i in range(times):
        a, b = optimize(a, b, x, y)
    return a, b

# STEP-1
# Initialize parameters and display
a = np.random.rand(1)
print("Initial a:", a)

b = np.random.rand(1)
print("Initial b:", b)

Lr = 1e-4

# for the first iteration, the parameter values, losses, and visualize after the iteration are displayed
a, b = iterate(a, b, x, y, 1)
prediction = model(a, b, x)
loss = loss_function(a, b, x, y)
print("After 1 iteration - a:", a, "b:", b, "loss:", loss)
plt.scatter(x, y)
plt.plot(x, prediction)
plt.show()

#STEP-2

a,b= iterate(a,b,x,y,2)
prediction = model(a,b,x)
loss=loss_function(a,b,x,y)
print(a,b,loss)
plt.scatter(x,y)
plt.plot(x,prediction)

# STEP-3

a,b= iterate(a,b,x,y,3)
prediction = model(a,b,x)
loss=loss_function(a,b,x,y)
print(a,b,loss)
plt.scatter(x,y)
plt.plot(x,prediction)

# STEP-4

a,b= iterate(a,b,x,y,4)
prediction = model(a,b,x)
loss=loss_function(a,b,x,y)
print(a,b,loss)
plt.scatter(x,y)
plt.plot(x,prediction)

# STEP-5

a,b= iterate(a,b,x,y,5)
prediction = model(a,b,x)
loss=loss_function(a,b,x,y)
print(a,b,loss)
plt.scatter(x,y)
plt.plot(x,prediction)

# STEP-6

a,b= iterate(a,b,x,y,10000)
prediction = model(a,b,x)
loss=loss_function(a,b,x,y)
print(a,b,loss)
plt.scatter(x,y)
plt.plot(x,prediction)